tidy_reviews
library(stringr)
library(here)
slides <- list.files(here("Rmd"), pattern="^[[:digit:]]")
slides
slides <- list.files(here("Rmd"), pattern="^[[:digit:]].*Rmd$")
slides
if (!dir.exists(here("script"))) {
dir.create(here("script"))
}
for (file in slides) {
path <- here("Rmd", file)
knitr::purl(path, output=here("script", str_replace(file,"md$","")))
}
library(stringr)
library(here)
slides <- list.files(here("Rmd"), pattern="^[[:digit:]].*Rmd$")
if (!dir.exists(here("script"))) {
dir.create(here("script"))
}
for (file in slides) {
path <- here("Rmd", file)
knitr::purl(path, output=here("script", str_replace(file,"md$","")))
}
if (!dir.exists(here("pdf"))) {
dir.create(here("pdf"))
}
library(stringr)
library(here)
if (!dir.exists(here("pdf"))) {
dir.create(here("pdf"))
}
pdf_slides <- list.files(here("Rmd"), pattern=".*pdf$")
for (file in pdf_slides) {
path <- here("Rmd", file)
file.copy(from=path, to=here("pdf"))
}
slides <- list.files(here("Rmd"), pattern="^[[:digit:]].*Rmd$")
if (!dir.exists(here("script"))) {
dir.create(here("script"))
}
for (file in slides) {
path <- here("Rmd", file)
knitr::purl(path, output=here("script", str_replace(file,"md$","")))
}
if (!dir.exists(here("pdf"))) {
dir.create(here("pdf"))
}
pdf_slides <- list.files(here("Rmd"), pattern=".*pdf$")
for (file in pdf_slides) {
path <- here("Rmd", file)
file.copy(from=path, to=here("pdf"))
file.remove(path)
}
library(here)
library(tidyverse)
library(tidytext)
text <- c('A company culture that encourages dissent, discourse, transparency, and fairness.',
'Strong compensation, from benefits, to perks, to base pay.',
'Decent internal mobility opportunities.',
'Employees are proud to work on globally impactful products, leading.'
)
text
text_df <- tibble(line = 1:4, text = text)
text_df
text_df %>%
unnest_tokens(word, text)
text_df <- tibble(text = text)
text_df
text_df %>%
unnest_tokens(word, text)
text_df <- tibble(line = 1:4, text = text)
text_df
text_df %>%
unnest_tokens(word, text)
text_df
text_df %>%
unnest_tokens(word, text, to_lower = FALSE)
text_df %>%
unnest_tokens(ngram, text, token="ngrams", n=2)
reviews <- read_csv(here("data/employee_reviews_10000.csv"))
reviews <- read_csv("../data/employee_reviews_10000.csv")
pwd
pwd()
cd()
get_cd()
get_wd()
wd()
getwd()
reviews <- read_csv("C:/Users/pablo.haya/Qsync/phaya/devel/intro-r-nlp/data/employee_reviews_10000.csv")
getwd()
glimpse(reviews)
head(reviews)
head(reviews$summary)
tidy_reviews <- reviews %>%
select(summary) %>%
unnest_tokens(word, summary)
print(tidy_reviews, n=5)
print(tidy_reviews)
tidy_reviews %>%
count(word, sort = TRUE)
data(stop_words)
print(stop_words)
tidy_reviews
tidy_reviews <- tidy_reviews %>%
anti_join(stop_words)
print(tidy_reviews)
tidy_reviews %>%
count(word, sort = TRUE)
stop_words
table(stop_words$lexicon)
stop_words_snowball <- stop_words %>%
filter(lexicon == "snowball")
stop_words_snowball
table(stop_words_snowball$lexicon)
tidy_reviews <- reviews %>%
select(summary) %>%
unnest_tokens(word, summary) %>%
anti_join(stop_words_snowball)
print(tidy_reviews)
tidy_reviews %>%
count(word, sort = TRUE)
tidy_reviews %>%
count(word, sort = TRUE) %>%
filter(n > 300)
tidy_reviews %>%
count(word, sort = TRUE) %>%
filter(n > 300) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word)) +
geom_col() +
labs(y = NULL)
get_sentiments("afinn")
get_sentiments("afinn") %>%
filter(value > 0)
library(here)
library(tidyverse)
library(tidytext)
library(reshape2)
get_sentiments("afinn")
get_sentiments("afinn") %>%
filter(value > 0)
reviews <- read_csv(here("data/employee_reviews_10000.csv"))
tidy_reviews <- reviews %>%
select(summary) %>%
unnest_tokens(word, summary)
print(tidy_reviews)
get_sentiments("nrc")
print(tidy_reviews)
get_sentiments("nrc")
nrc_joy <- get_sentiments("nrc") %>%
filter(sentiment == "joy")
print(nrc_joy)
tidy_reviews
nrc_joy
tidy_reviews %>%
inner_join(nrc_joy)
tidy_reviews
tidy_reviews %>%
inner_join(nrc_joy)
nrc_joy
tidy_reviews
nrc_joy
tidy_reviews %>%
inner_join(nrc_joy)
tidy_reviews %>%
inner_join(nrc_joy) %>%
count(word, sort = TRUE)
get_sentiments("nrc")
nrc <- get_sentiments("nrc")
table(nrc$sentiment)
glimpse(reviews)
tidy_reviews
reviews %>%
select(company, summary)
reviews %>%
select(company, summary) %>%
mutate(id_review = row_number())
reviews %>%
select(company, summary)
reviews %>%
select(company, summary)%>%
mutate(id_review = row_number())
reviews %>%
select(company, summary)%>%
mutate(id_review = row_number()) %>%
unnest_tokens(word, summary)
tidy_reviews <- reviews %>%
select(company, summary)%>%
mutate(id_review = row_number()) %>%
unnest_tokens(word, summary)
tidy_reviews
get_sentiments("bing")
bing <- get_sentiments("bing")
table(bing$sentiment)
bing <- get_sentiments("bing")
tidy_reviews %>%
inner_join(bing)
tidy_reviews
bing
tidy_reviews %>%
inner_join(bing) %>%
count(company, id_review, sentiment)
reviews_sentiment <- tidy_reviews %>%
inner_join(get_sentiments("bing"))  %>%
count(company, id_review, sentiment) %>%
pivot_wider(names_from = sentiment,
values_from = n,
values_fill = 0) %>%
mutate(sentiment = positive - negative)
reviews_sentiment <- tidy_reviews %>%
inner_join(get_sentiments("bing"))  %>%
count(company, id_review, sentiment) %>%
pivot_wider(names_from = sentiment,
values_from = n,
values_fill = 0) %>%
mutate(sentiment = positive - negative)
reviews_sentiment
tidy_reviews %>%
inner_join(bing) %>%
count(company, id_review, sentiment)
bing <- get_sentiments("bing")
bing
tidy_reviews %>%
inner_join(bing)
tidy_reviews %>%
inner_join(bing) %>%
count(company, id_review, sentiment)
tidy_reviews %>%
inner_join(bing) %>%
count(company, id_review, sentiment) %>%
pivot_wider(names_from = sentiment,
values_from = n,
values_fill = 0)
tidy_reviews %>%
inner_join(bing) %>%
count(company, id_review, sentiment) %>%
pivot_wider(names_from = sentiment,
values_from = n,
values_fill = 0) %>%
mutate(sentiment = positive - negative)
reviews_sentiment <- tidy_reviews %>%
inner_join(bing) %>%
count(company, id_review, sentiment) %>%
pivot_wider(names_from = sentiment,
values_from = n,
values_fill = 0) %>%
mutate(sentiment = positive - negative)
reviews_sentiment
reviews_sentiment$sentiment
reviews_sentiment %>%
ggplot(aes(sentiment, fill = company)) +
geom_histogram(show.legend = FALSE)  +
facet_wrap(~company, ncol = 2, scales = "free_x")
reviews
table(reviews$company)
tidy_reviews
tidy_reviews %>%
inner_join(get_sentiments("bing"))
tidy_reviews %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE)
tidy_reviews %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
bing_word_counts <- tidy_reviews %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
bing_word_counts %>%
group_by(sentiment) %>%
slice_max(n, n = 10) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(~sentiment, scales = "free_y") +
labs(x = "Contribution to sentiment",
y = NULL)
bing_word_counts
bing_word_counts %>%
group_by(sentiment) %>%
slice_max(n, n = 10)
bing_word_counts %>%
group_by(sentiment) %>%
slice_max(n, n = 10) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(~sentiment, scales = "free_y") +
labs(x = "Contribution to sentiment",
y = NULL)
bing_word_counts %>%
group_by(sentiment) %>%
slice_max(n, n = 5) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(~sentiment, scales = "free_y") +
labs(x = "Contribution to sentiment",
y = NULL)
bing_word_counts %>%
group_by(sentiment) %>%
slice_max(n, n = 10) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(~sentiment, scales = "free_y") +
labs(x = "Contribution to sentiment",
y = NULL)
library(wordcloud)
tidy_reviews %>%
count(word)
tidy_reviews %>%
count(word) %>%
with(wordcloud(word, n, max.words = 50))
tidy_reviews %>%
anti_join(stop_words) %>%
count(word) %>%
with(wordcloud(word, n, max.words = 50))
stop_words
tibble(
word = c("company"),
lexicon = c("propio")
)
tibble(
word = c("experience"),
lexicon = c("propio")
)
bind_rows(tibble(
word = c("experience"),
lexicon = c("propio")
), stop_words)
custom_stop_words <- bind_rows(tibble(
word = c("experience"),
lexicon = c("propio")
), stop_words)
custom_stop_words
table(custom_stop_words$lexicon)
custom_stop_words %>% filter(lexicon == "propio")
tidy_reviews %>%
anti_join(custom_stop_words) %>%
count(word) %>%
with(wordcloud(word, n, max.words = 50))
tidy_reviews %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("red", "green"),
max.words = 50)
594/15415
reviews <- read_csv(here("data/employee_reviews_10000.csv"))
tidy_reviews <- reviews %>%
select(company, summary) %>%
unnest_tokens(word, summary)
tidy_reviews
reviews_words <- tidy_reviews %>%
count(company, word, sort = TRUE)
reviews_tf_idf <- reviews_words %>%
filter(company != 'facebook', company != 'netflix') %>%
bind_tf_idf(word, company, n)
reviews_tf_idf
reviews_tf_idf %>% arrange(idf)
reviews_tf_idf %>% arrange(desc(idf))
library(here)
library(tidyverse)
library(tidytext)
library(forcats)
reviews <- read_csv(here("data/employee_reviews_10000.csv"))
tidy_reviews <- reviews %>%
select(company, summary) %>%
unnest_tokens(word, summary)
tidy_reviews
reviews_words <- tidy_reviews %>%
count(company, word, sort = TRUE)
reviews_words
reviews_tf_idf <- reviews_words %>%
filter(company != 'facebook', company != 'netflix')
reviews_tf_idf
table(reviews_tf_idf$company)
reviews_tf_idf <- reviews_words %>%
filter(company != 'facebook', company != 'netflix') %>%
bind_tf_idf(word, company, n)
print(reviews_tf_idf)
594 / 15415
reviews_tf_idf %>%
arrange(desc(tf_idf))
reviews_tf_idf %>%
group_by(company) %>%
slice_max(tf_idf, n = 15) %>%
ungroup() %>%
ggplot(aes(tf_idf, reorder_within(word, tf_idf, company), fill = company)) +
geom_col(show.legend = FALSE) +
facet_wrap(~company, ncol = 2, scales = "free") +
scale_y_reordered() +
labs(x = "tf-idf", y = NULL)
library(here)
library(rmarkdown)
library(tidyverse)
slides <- list.files(here("Rmd"), pattern="^[[:digit:]]")
slides
if (!dir.exists(here("pdf"))) {
dir.create(here("pdf"))
}
# render to beamer presentation
for (file in slides) {
path <- here("Rmd", file)
render(path, beamer_presentation(theme= "CambridgeUS",
colortheme= "orchid",
fonttheme= "structurebold"),
output_dir=here("pdf"))
}
install.packages("textdata")
# render to beamer presentation
for (file in slides) {
path <- here("Rmd", file)
render(path, beamer_presentation(theme= "CambridgeUS",
colortheme= "orchid",
fonttheme= "structurebold"),
output_dir=here("pdf"))
}
if (!dir.exists(here("html"))) {
dir.create(here("html"))
}
for (file in slides) {
path <- here("Rmd",file)
render(path, ioslides_presentation(widescreen = TRUE), output_dir=here("html"))
}
file.copy(here("html"), here("dist"), recursive=TRUE)
if (!dir.exists(here("dist/data"))) {
dir.create(here("dist/data"))
}
file.copy(here("data/employee_reviews_10000.csv"), here("dist/data"))
zip(zipfile = here("test.zip"), files = here("dist"))
zip(zipfile = here("test.zip"), files = "dist")
zip(zipfile = here("2023-hr-analytics-nlp.zip"), files = "dist")
if (!dir.exists(here("dist"))) {
dir.create(here("dist"))
}
file.copy(here("pdf"), here("dist"), recursive=TRUE)
file.copy(here("html"), here("dist"), recursive=TRUE)
file.copy(here("script"), here("dist"), recursive=TRUE)
if (!dir.exists(here("dist/data"))) {
dir.create(here("dist/data"))
}
file.copy(here("data/employee_reviews_10000.csv"), here("dist/data"))
zip(zipfile = here("2023-hr-analytics-nlp.zip"), files = "dist")
library(here)
library(rmarkdown)
library(tidyverse)
slides <- list.files(here("Rmd"), pattern="^[[:digit:]]")
################################################################################
# Render slides to pdfs
################################################################################
if (!dir.exists(here("pdf"))) {
dir.create(here("pdf"))
}
# render to beamer presentation
for (file in slides) {
path <- here("Rmd", file)
render(path, beamer_presentation(theme= "CambridgeUS",
colortheme= "orchid",
fonttheme= "structurebold"),
output_dir=here("pdf"))
}
################################################################################
# Render slides to html
################################################################################
if (!dir.exists(here("html"))) {
dir.create(here("html"))
}
for (file in slides) {
path <- here("Rmd",file)
render(path, ioslides_presentation(widescreen = TRUE), output_dir=here("html"))
}
################################################################################
# Render README to gitbub README
################################################################################
render(here("Rmd","README.Rmd"), "md_document", encoding = "UTF-8", output_dir=here())
################################################################################
# Render README to html
################################################################################
render(here("Rmd","README.Rmd"), "html_document", encoding = "UTF-8", output_dir=here("html"))
################################################################################
# Render script
################################################################################
library(stringr)
if (!dir.exists(here("script"))) {
dir.create(here("script"))
}
for (file in slides) {
path <- here("Rmd", file)
knitr::purl(path, output=here("script", str_replace(file,"md$","")))
}
################################################################################
# Make distribution file
################################################################################
if (!dir.exists(here("dist"))) {
dir.create(here("dist"))
}
file.copy(here("pdf"), here("dist"), recursive=TRUE)
file.copy(here("html"), here("dist"), recursive=TRUE)
file.copy(here("script"), here("dist"), recursive=TRUE)
if (!dir.exists(here("dist/data"))) {
dir.create(here("dist/data"))
}
file.copy(here("data/employee_reviews_10000.csv"), here("dist/data"))
zip(zipfile = here("2023-hr-analytics-nlp.zip"), files = "dist")
