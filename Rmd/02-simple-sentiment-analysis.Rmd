---
title: "Análisis de sentimiento"
subtitle: "HR Analytics: Teoría y Práctica"
author: "http://pablohaya.com/contact"
date: "01/2023"
output:
  beamer_presentation: default
  ioslides_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(here)
library(tidyverse)
library(tidytext)
library(reshape2)
```

## Introducción

Vamos a ver un ejemplo más avanzado aunque manteniendo la simplicidad en cuanto a nuestra aproximación analítica.

Una manera de analizar el sentimiento que expresa un texto es asignar a cada palabra una polaridad, esto si, si es positiva, negativa o neutra. El sentimiento de una oración sería la suma de las aportaciones individuales de cada palabra.

---

El paquete `tidyverse` viene con tres lexicones en inglés de propósito general incorporados que asignan a cada palabra una polaridad.

* `AFINN`: las puntuaciones varían entre -5 y 5.
* `bing`: cada palabra puede ser positiva o negativa. Incluye también emociones
* `nrc`: cada palabra puede ser positiva o negativa. 

---

La función `get_sentiments()` permite obtener cada uno de estos lexicones. Probar a visualizar el formato de los otros dos lexicones.

```{r, echo = TRUE}
get_sentiments("afinn")
```

---

Leemos de nuevo el *dataset*, y tokenizamos la columna `summary`
```{r eval=FALSE, echo=TRUE}
reviews <- read_csv(here("data/employee_reviews_10000.csv"))

tidy_reviews <- reviews %>% 
  select(summary) %>% 
  unnest_tokens(word, summary)

tidy_reviews
```
```{r echo=FALSE, message=FALSE}
reviews <- read_csv(here("data/employee_reviews_10000.csv"))

tidy_reviews <- reviews %>% 
  select(summary) %>% 
  unnest_tokens(word, summary)

print(tidy_reviews, n=6)
```

---

Obtenemos todas las palabras etiquetadas como `joy` en el lexicon `nrc`

```{r eval=FALSE, echo=TRUE}
nrc_joy <- get_sentiments("nrc") %>% 
  filter(sentiment == "joy")

nrc_joy
```

```{r echo=FALSE}
nrc_joy <- get_sentiments("nrc") %>% 
  filter(sentiment == "joy")

print(nrc_joy, n=6)
```

---

Nos quedamos unicamente con aquellas palabras que coinciden con el conjunto de palabras que representan a la emoción `joy`, y visualizamos su frecuencia absoluta:

```{r echo=TRUE}
tidy_reviews %>%
  inner_join(nrc_joy) %>%
  count(word, sort = TRUE)
```
## A practicar

**Ejercicio**. Repetir los análisis con las columnas `pros` y `cons`.

## Distribución sentimiento por compañia

Hasta ahora hemos contemplado análisis que tienen en cuenta todos los textos de una columna (`summary`) en nuestro ejemplo. Ahora vamos a realizar análisis por cada comentario. Es preciso guardar para cada palabra el identificador del comentario al que pertenece. En nuestro ejemplo, será el número de línea. 

Además, vamos a incluir también la compañía a la que hace referencia el comentario.

```{r eval=FALSE, echo=TRUE}
tidy_reviews <- reviews %>% 
  select(company, summary) %>%
  mutate(id_review = row_number()) %>%
  unnest_tokens(word, summary)

tidy_reviews
```

---

```{r echo=FALSE}
tidy_reviews <- reviews %>% 
  select(company, summary) %>%
  mutate(id_review = row_number()) %>%
  unnest_tokens(word, summary)

print(tidy_reviews, n=10)
```

---

Vamos a realizar análisis de sentimiento empleando el lexicon `bing`

```{r eval=FALSE, echo=TRUE}
reviews_sentiment <- tidy_reviews %>%
  inner_join(get_sentiments("bing"))  %>%
  count(company, id_review, sentiment) %>%
  pivot_wider(names_from = sentiment, 
              values_from = n, 
              values_fill = 0) %>% 
  mutate(sentiment = positive - negative)

reviews_sentiment
```

---

```{r echo=FALSE}
reviews_sentiment <- tidy_reviews %>%
  inner_join(get_sentiments("bing"))  %>%
  count(company, id_review, sentiment) %>%
  pivot_wider(names_from = sentiment, 
              values_from = n, 
              values_fill = 0) %>% 
  mutate(sentiment = positive - negative)

reviews_sentiment
```

---

Visualizamos los histogramas de frecuencia de palabras por cada compañía

```{r eval=FALSE, echo=TRUE}
ggplot(reviews_sentiment, aes(sentiment, fill = company)) +
  geom_histogram(show.legend = FALSE)  +
  facet_wrap(~company, ncol = 2, scales = "free_x")
```

---

```{r echo=FALSE, message=FALSE}
ggplot(reviews_sentiment, aes(sentiment, fill = company)) +
  geom_histogram(show.legend = FALSE)  +
  facet_wrap(~company, ncol = 2, scales = "free_x")
```

## Palabras positivas y negativas más frecuentes

Analizamoslos términos positivos y negativos por separado

```{r echo=TRUE}
bing_word_counts <- tidy_reviews %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

bing_word_counts
```

---

La siguiente gráfica muestra como contribuyen los términos más frecuentes al sentimiento:

```{r eval=FALSE, echo=TRUE}
bing_word_counts %>%
  group_by(sentiment) %>%
  slice_max(n, n = 10) %>% 
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(x = "Contribution to sentiment",
       y = NULL)
```

---

```{r echo=FALSE}
bing_word_counts %>%
  group_by(sentiment) %>%
  slice_max(n, n = 10) %>% 
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(x = "Contribution to sentiment",
       y = NULL)
```


## Nubes de palabras

Es preciso instalar el paquete `wordcloud` que dependiendo de la versión de R puede ser un poco complejo. Probar primero:

* install.packages("slam")
* install.packages("wordcloud")

---

Si no funciona hay que instalar primero las Rtools

* Como instalar las RTools: https://cran.r-project.org/bin/windows/Rtools/rtools40.html

Recordar realizar el paso de actualizar el `PATH` y reiniciar `R`

Instalar el paquete `devtools`

* `install.packages("devtools")`

y finalmente instalar desde la consola de RStudio: [`wordcloud`](https://cran.r-project.org/web/packages/wordcloud/readme/README.html)

* `devtools::install_github("ifellows/wordcloud")`

---

Una vez instalado el paquete, visualizar una nube de palabras es muy sencillo:

```{r eval=FALSE, echo=TRUE}
library(wordcloud)

tidy_reviews %>%
  anti_join(stop_words) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 50))
```

---

```{r echo=FALSE, message=FALSE}
library(wordcloud)

tidy_reviews %>%
  anti_join(stop_words) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 50))
```

---

Podemos incorporar palabras prohibidas que quisieramos eliminar

```{r eval=FALSE, echo=TRUE}
custom_stop_words <- bind_rows(tibble(
                                word = c("company"),  
                                lexicon = c("propio")
                               ), 
                               stop_words)
custom_stop_words
```
```{r echo=FALSE}
custom_stop_words <- bind_rows(tibble(
                                word = c("company"),  
                                lexicon = c("propio")
                               ), 
                               stop_words)
print(custom_stop_words, n=6)
```

---

Mostramos la nueva nube de palabras habiendo eliminado `company`

```{r eval=FALSE, echo=TRUE}
tidy_reviews %>%
  anti_join(custom_stop_words) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 50))
```

---

```{r echo=FALSE, message=FALSE}
tidy_reviews %>%
  anti_join(custom_stop_words) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 50))
```

---

Mismo gráfico pero destacando los términos positivo y negativo

```{r eval=FALSE, echo=TRUE}
tidy_reviews %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("red", "green"),
                   max.words = 50)
```

---

```{r echo=FALSE, message=FALSE}
tidy_reviews %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("red", "green"),
                   max.words = 50)
```
